{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Copy of mapreduce1_word_frequency_and_sort.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Migaalee/hadoop/blob/main/Copy_of_mapreduce1_word_frequency_and_sort.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNSHH6VJfZe3"
      },
      "source": [
        "# Python MapReduce Exercise\n",
        "\n",
        "In the notebook, you should create a map-reduce program that count the number of occurrence of each word.\n",
        "\n",
        "In this exercise, hadoop runs in standalone mode and reads data from the local filesystem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ8Nw-gbfZe4"
      },
      "source": [
        "### Download the dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TS-EzyXPfZe5"
      },
      "source": [
        "!wget -O os_maias.txt https://www.dropbox.com/s/n24v0z7y79np319/os_maias.txt?dl=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlRcV-eufZe9"
      },
      "source": [
        "## WordCount Example\n",
        "Read the words from input and count the number of occurrences of each word.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBsLT4AffZe-"
      },
      "source": [
        "### Mapper\n",
        "Complete with the code for the mapper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMVCdgkzfZe_"
      },
      "source": [
        "%%file mapper_words.py\n",
        "#!/usr/bin/env python\n",
        "\n",
        "# to be completed\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TXds5bPfZfD"
      },
      "source": [
        "### Reducer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsEVN_s7fZfD"
      },
      "source": [
        "%%file reducer_words.py\n",
        "#!/usr/bin/python\n",
        "\n",
        "# to be completed\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQsiHW7HfZfH"
      },
      "source": [
        "### Hadoop standalone mode execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv0xLDpVfZfI"
      },
      "source": [
        "\n",
        "The output directory needs to be cleared..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP1Fhdd0fZfJ"
      },
      "source": [
        "rm -rf results_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHw7F_WnfZfO"
      },
      "source": [
        "#### Submitting the job\n",
        "\n",
        "The _hadoop_ command is used to submit the mapreduce job to the cluster..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "090VJwItfZfO"
      },
      "source": [
        "!hadoop jar /opt/hadoop-3.2.0/share/hadoop/tools/lib/hadoop-*streaming*.jar -files mapper_words.py,reducer_words.py -mapper mapper_words.py -reducer reducer_words.py -input os_maias.txt -output results_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ilgmk1UWfZfW"
      },
      "source": [
        "#### Checking the results\n",
        "The result is stored in directory results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsA2tylZfZfX"
      },
      "source": [
        "!cat results_words/part-*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOQUXJG0fZfe"
      },
      "source": [
        "## Sorting\n",
        "The results are not sorted. Let's sort them by frequency (the words with higher occurrence first)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWPo80cWfZff"
      },
      "source": [
        "### Mapper\n",
        "Complete with the code for the mapper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjqkYn5wfZfg"
      },
      "source": [
        "%%file mapper_sort.py\n",
        "#!/usr/bin/env python\n",
        "\n",
        "# to be completed\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga45-R37fZfl"
      },
      "source": [
        "### Reducer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYyVhxuvfZfm"
      },
      "source": [
        "%%file reducer_sort.py\n",
        "#!/usr/bin/python\n",
        "\n",
        "# to be completed\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQTmstyDfZfp"
      },
      "source": [
        "### Hadoop standalone mode execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z4_LRmAfZfp"
      },
      "source": [
        "\n",
        "The output directory needs to be cleared..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMYwswyPfZfq"
      },
      "source": [
        "rm -rf results_sort"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuDJamQffZft"
      },
      "source": [
        "#### Submitting the job\n",
        "\n",
        "The _hadoop_ command is used to submit the mapreduce job to the cluster..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "QohisrrDfZfu"
      },
      "source": [
        "!hadoop jar /opt/hadoop-3.2.0/share/hadoop/tools/lib/hadoop-*streaming*.jar -files mapper_sort.py,reducer_sort.py -mapper mapper_sort.py -reducer reducer_sort.py -input results_words/part-* -output results_sort"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHrXVhYJfZfy"
      },
      "source": [
        "#### Checking the results\n",
        "The result is stored in directory results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0D1nvntsfZf0"
      },
      "source": [
        "!cat results_sort/part-*"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}